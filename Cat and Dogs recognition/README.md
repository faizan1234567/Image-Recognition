cats and dogs classification
In [CatsvsDogsClassifier.ipynb](https://github.com/faizan1234567/Image-Recognition/blob/main/Cat%20and%20Dogs%20recognition/CatsvsDogsClassifier.ipynb) cats and dogs dataset has been downloaded. This dataset has two classes manily cats and dogs. There are 2000 images for training and 1000 images for validation. After loading and preprocessing data, a custom CNN model was designed using keras sequential API, in the model architecture 3 convolution, 3 max-pooling and 2 fully connected layes has been added.

Since the dataset is small, in order to get good results we need to add more examples in the training set. But getting examples is not easy, one way we can make our dataset more diverse by using data augmentation option. In CatsvsDogsClassifier.ipynb notebook, I have not added data augmentation options for comparison purposes. The model has been trained without data augmentation, and it got 98% training accuracy and 70% validation accuracy. In this case, the model is overfitting. I will address this issue in the next notebook.

Overfitting is a serious problem in machine leanring. In oder to address this issue, I added data augmentation in [cats_vs_dogs_classification_97%_on_validation.ipynb](https://github.com/faizan1234567/Image-Recognition/blob/main/Cat%20and%20Dogs%20recognition/cats_vs_dogs_classification_97%25_on_validation.ipynb) notebook. As the dataset size is small, therefore data augmentation will make our training set more diverse. The model will see images rotated, translasted, zoomed, fliped, and sheared images. Which will resemable the real world scenario.

The model I trained in the previous notebook was pretty simple. However, in this notebook I trained [InceptionV3](https://arxiv.org/abs/1512.00567) model. Which has been trained on imagenet dataset with 1.2 million images and 1000 classes. Hence I am trying to recognize cats vs dogs in an images so I changed it's last layer with 2 classes. Following that, Weights of earlier layres have been freezed and only the last layer have been trained on the dataset for 20 epochs.

The model performance significantly improved by using transfer learning and data augmentation. In the later example, the model acheived 97% validation accuracy.
