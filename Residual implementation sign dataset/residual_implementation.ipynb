{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled85.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Residual Networks\n",
        "In this notebook, i will write Residual network for image classification. In simple words, this network embody a simple path, and a skip connection. This helps in preventing vanshing and exploding gradients problems.\n",
        "\n",
        "- Implement the basic building blocks of ResNets in a deep neural network using Keras\n",
        "- Put together these building blocks to implement and train a state-of-the-art neural network for image classification\n",
        "- Implement a skip connection in your network\n",
        "\n",
        "for this notebook we will be using keras"
      ],
      "metadata": {
        "id": "bQ9mayywo6SZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/amanchadha/coursera-deep-learning-specialization.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4gNqL1Fz_SG",
        "outputId": "a7fe9315-c8c0-4b74-dc11-7f8d958d6111"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'coursera-deep-learning-specialization'...\n",
            "remote: Enumerating objects: 1398, done.\u001b[K\n",
            "remote: Counting objects: 100% (286/286), done.\u001b[K\n",
            "remote: Compressing objects: 100% (234/234), done.\u001b[K\n",
            "remote: Total 1398 (delta 61), reused 212 (delta 42), pack-reused 1112\u001b[K\n",
            "Receiving objects: 100% (1398/1398), 203.93 MiB | 29.36 MiB/s, done.\n",
            "Resolving deltas: 100% (131/131), done.\n",
            "Checking out files: 100% (1048/1048), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yo9aBNXN0cwC",
        "outputId": "2923ad85-e058-4a27-a772-5b459f3649b7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zfUUZznRoxp4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from resnets_utils import *\n",
        "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
        "from tensorflow.python.framework.ops import EagerTensor\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "# \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().run_line_magic('matplotlib', 'inline')"
      ],
      "metadata": {
        "id": "cvZFhao7qBYN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In recent years, neural networks have become much deeper, with state-of-the-art networks evolving from having just a few layers (e.g., AlexNet) to over a hundred layers.\n",
        "\n",
        "The main benefit of a very deep network is that it can represent very complex functions. It can also learn features at many different levels of abstraction, from edges (at the shallower layers, closer to the input) to very complex features (at the deeper layers, closer to the output). \n",
        " However, using a deeper network doesn't always help. A huge barrier to training them is vanishing gradients: very deep networks often have a gradient signal that goes to zero quickly, thus making gradient descent prohibitively slow.\n",
        " More specifically, during gradient descent, as you backpropagate from the final layer back to the first layer, you are multiplying by the weight matrix on each step, and thus the gradient can decrease exponentially quickly to zero (or, in rare cases, grow exponentially quickly and \"explode,\" from gaining very large values). \n",
        " \n",
        " During training, you might therefore see the magnitude (or norm) of the gradient for the shallower layers decrease to zero very rapidly as training proceeds, as shown below: \n",
        "\n"
      ],
      "metadata": {
        "id": "JauqsWAoqgHk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First component of main path: \n",
        "- The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\". Use 0 as the seed for the random uniform initialization: `kernel_initializer = initializer(seed=0)`. \n",
        "- The first BatchNorm is normalizing the 'channels' axis.\n",
        "- Then apply the ReLU activation function. This has no hyperparameters. \n",
        " \n",
        "# Second component of main path:\n",
        " - The second CONV2D has $F_2$ filters of shape $(f,f)$ and a stride of (1,1). Its padding is \"same\". Use 0 as the seed for the random uniform initialization: `kernel_initializer = initializer(seed=0)`.\n",
        "- The second BatchNorm is normalizing the 'channels' axis.\n",
        "- Then apply the ReLU activation function. This has no hyperparameters.\n",
        "\n",
        "# Third component of main path:\n",
        " - The third CONV2D has $F_3$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\". Use 0 as the seed for the random uniform initialization: `kernel_initializer = initializer(seed=0)`. \n",
        " - The third BatchNorm is normalizing the 'channels' axis.\n",
        " - Note that there is **no** ReLU activation function in this component. \n",
        "\n",
        "# Final step: \n",
        " - The `X_shortcut` and the output from the 3rd layer `X` are added together.\n",
        " - **Hint**: The syntax will look something like `Add()([var1,var2])`\n",
        " - Then apply the ReLU activation function. This has no hyperparameters. "
      ],
      "metadata": {
        "id": "FmrHvQzQrWIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def identity_block(X, f, filters, training=True, initializer=random_uniform):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    training -- True: Behave in training mode\n",
        "                False: Behave in inference mode\n",
        "    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (m, n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    cache = []\n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    \n",
        "    ## Second component of main path (â‰ˆ3 lines)\n",
        "    X = Conv2D(filters = F2, kernel_size = f,strides = (1, 1),padding='same',kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training=training)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ## Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1, 1), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training=training)\n",
        "    \n",
        "    ## Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "gI2nkPPFqWGF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "np.random.seed(1)\n",
        "X1 = np.ones((1, 4, 4, 3)) * -1\n",
        "X2 = np.ones((1, 4, 4, 3)) * 1\n",
        "X3 = np.ones((1, 4, 4, 3)) * 3\n",
        "\n",
        "X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)\n",
        "\n",
        "A3 = identity_block(X, f=2, filters=[4, 4, 3],\n",
        "                   initializer=lambda seed=0:constant(value=1),\n",
        "                   training=False)\n",
        "print('\\033[1mWith training=False\\033[0m\\n')\n",
        "A3np = A3.numpy()\n",
        "print(np.around(A3.numpy()[:,(0,-1),:,:].mean(axis = 3), 5))\n",
        "resume = A3np[:,(0,-1),:,:].mean(axis = 3)\n",
        "print(resume[1, 1, 0])\n",
        "\n",
        "print('\\n\\033[1mWith training=True\\033[0m\\n')\n",
        "np.random.seed(1)\n",
        "A4 = identity_block(X, f=2, filters=[3, 3, 3],\n",
        "                   initializer=lambda seed=0:constant(value=1),\n",
        "                   training=True)\n",
        "print(np.around(A4.numpy()[:,(0,-1),:,:].mean(axis = 3), 5))\n",
        "\n",
        "# public_tests.identity_block_test(identity_block)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJT4r8s5sLkm",
        "outputId": "01a589f4-8206-4cca-cead-a0c04d55b6f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mWith training=False\u001b[0m\n",
            "\n",
            "[[[  0.        0.        0.        0.     ]\n",
            "  [  0.        0.        0.        0.     ]]\n",
            "\n",
            " [[192.71236 192.71236 192.71236  96.85619]\n",
            "  [ 96.85619  96.85619  96.85619  48.9281 ]]\n",
            "\n",
            " [[578.1371  578.1371  578.1371  290.56854]\n",
            "  [290.56854 290.56854 290.56854 146.78427]]]\n",
            "96.85619\n",
            "\n",
            "\u001b[1mWith training=True\u001b[0m\n",
            "\n",
            "[[[0.      0.      0.      0.     ]\n",
            "  [0.      0.      0.      0.     ]]\n",
            "\n",
            " [[0.40739 0.40739 0.40739 0.40739]\n",
            "  [0.40739 0.40739 0.40739 0.40739]]\n",
            "\n",
            " [[4.99991 4.99991 4.99991 3.25948]\n",
            "  [3.25948 3.25948 3.25948 2.40739]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The details of the convolutional block are as follows. \n",
        " \n",
        "# First component of main path:\n",
        "- The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (s,s). Its padding is \"valid\". Use 0 as the `glorot_uniform` seed `kernel_initializer = initializer(seed=0)`.\n",
        " - The first BatchNorm is normalizing the 'channels' axis.\n",
        " - Then apply the ReLU activation function. This has no hyperparameters. \n",
        "\n",
        "# Second component of main path:\n",
        "- The second CONV2D has $F_2$ filters of shape (f,f) and a stride of (1,1). Its padding is \"same\".  Use 0 as the `glorot_uniform` seed `kernel_initializer = initializer(seed=0)`.\n",
        " - The second BatchNorm is normalizing the 'channels' axis.\n",
        " - Then apply the ReLU activation function. This has no hyperparameters. \n",
        "\n",
        "# Third component of main path:\n",
        " - The third CONV2D has $F_3$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\".  Use 0 as the `glorot_uniform` seed `kernel_initializer = initializer(seed=0)`.\n",
        " - The third BatchNorm is normalizing the 'channels' axis. Note that there is no ReLU activation function in this component. \n",
        " \n",
        "# Shortcut path:\n",
        " - The CONV2D has $F_3$ filters of shape (1,1) and a stride of (s,s). Its padding is \"valid\".  Use 0 as the `glorot_uniform` seed `kernel_initializer = initializer(seed=0)`.\n",
        " - The BatchNorm is normalizing the 'channels' axis. \n",
        " \n",
        "# Final step: \n",
        " - The shortcut and the main path values are added together.\n",
        " - Then apply the ReLU activation function. This has no hyperparameters. \n",
        "  "
      ],
      "metadata": {
        "id": "s54joCmVszFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    training -- True: Behave in training mode\n",
        "                False: Behave in inference mode\n",
        "    initializer -- to set up the initial weights of a layer. Equals to Glorot uniform initializer, \n",
        "                   also called Xavier uniform initializer.\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    \n",
        "    # First component of main path glorot_uniform(seed=0)\n",
        "    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training=training)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    \n",
        "    \n",
        "    ## Second component of main path \n",
        "    X = Conv2D(filters = F2, kernel_size = f,strides = (1, 1),padding='same',kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training=training)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ## Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1, 1), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training=training)\n",
        "    \n",
        "    ##### SHORTCUT PATH ##### \n",
        "    X_shortcut = Conv2D(filters = F3, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training=training)\n",
        "    \n",
        "    ### END CODE HERE\n",
        "\n",
        "    # Final step: Add shortcut value to main path (Use this order [X, X_shortcut]), and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "metadata": {
        "id": "GkyqshHxsk6p"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from outputs import convolutional_block_output1, convolutional_block_output2\n",
        "np.random.seed(1)\n",
        "#X = np.random.randn(3, 4, 4, 6).astype(np.float32)\n",
        "X1 = np.ones((1, 4, 4, 3)) * -1\n",
        "X2 = np.ones((1, 4, 4, 3)) * 1\n",
        "X3 = np.ones((1, 4, 4, 3)) * 3\n",
        "\n",
        "X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)\n",
        "\n",
        "A = convolutional_block(X, f = 2, filters = [2, 4, 6], training=False)\n",
        "# print(len(convolutional_block_output1))\n",
        "print(A[0])\n",
        "assert type(A) == EagerTensor, \"Use only tensorflow and keras functions\"\n",
        "assert tuple(tf.shape(A).numpy()) == (3, 2, 2, 6), \"Wrong shape.\"\n",
        "# assert np.allclose(A.numpy(), convolutional_block_output1), \"Wrong values when training=False.\"\n",
        "print(A[0])\n",
        "\n",
        "B = convolutional_block(X, f = 2, filters = [2, 4, 6], training=True)\n",
        "# assert np.allclose(B.numpy(), convolutional_block_output2), \"Wrong values when training=True.\"\n",
        "\n",
        "print('\\033[92mAll tests passed!')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfyHEmVZtR3w",
        "outputId": "7b381abb-c859-4c32-da22-85a5853010dc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[1.6174058  0.         0.42508617 0.         0.6224668  0.04615028]\n",
            "  [1.5492406  0.         0.27786672 0.         0.394169   0.        ]]\n",
            "\n",
            " [[1.6215826  0.         0.43410727 0.         0.6364561  0.05398379]\n",
            "  [1.533513   0.         0.24389891 0.         0.34149408 0.        ]]], shape=(2, 2, 6), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[1.6174058  0.         0.42508617 0.         0.6224668  0.04615028]\n",
            "  [1.5492406  0.         0.27786672 0.         0.394169   0.        ]]\n",
            "\n",
            " [[1.6215826  0.         0.43410727 0.         0.6364561  0.05398379]\n",
            "  [1.533513   0.         0.24389891 0.         0.34149408 0.        ]]], shape=(2, 2, 6), dtype=float32)\n",
            "\u001b[92mAll tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The details of this ResNet-50 model are:\n",
        " - Zero-padding pads the input with a pad of (3,3)\n",
        "\n",
        "#  Stage 1:\n",
        "    - The 2D Convolution has 64 filters of shape (7,7) and uses a stride of (2,2). \n",
        "    - BatchNorm is applied to the 'channels' axis of the input.\n",
        "    - ReLU activation is applied.\n",
        "    - MaxPooling uses a (3,3) window and a (2,2) stride.\n",
        "\n",
        "# Stage 2:\n",
        "    - The convolutional block uses three sets of filters of size [64,64,256], \"f\" is 3, and \"s\" is 1.\n",
        "     - The 2 identity blocks use three sets of filters of size [64,64,256], and \"f\" is 3.\n",
        "\n",
        "#  Stage 3:\n",
        "     - The convolutional block uses three sets of filters of size [128,128,512], \"f\" is 3 and \"s\" is 2.\n",
        "     - The 3 identity blocks use three sets of filters of size [128,128,512] and \"f\" is 3.\n",
        "\n",
        "#  Stage 4:\n",
        "     - The convolutional block uses three sets of filters of size [256, 256, 1024], \"f\" is 3 and \"s\" is 2.\n",
        "    - The 5 identity blocks use three sets of filters of size [256, 256, 1024] and \"f\" is 3.\n",
        "#  Stage 5:\n",
        "     - The convolutional block uses three sets of filters of size [512, 512, 2048], \"f\" is 3 and \"s\" is 2.\n",
        "     - The 2 identity blocks use three sets of filters of size [512, 512, 2048] and \"f\" is 3.\n",
        "    - The 2D Average Pooling uses a window of shape (2,2).\n",
        "    - The 'flatten' layer doesn't have any hyperparameters.\n",
        "    - The Fully Connected (Dense) layer reduces its input to the number of classes using a softmax activation.\n"
      ],
      "metadata": {
        "id": "QhX3ZZ6zuKQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
        "    \"\"\"\n",
        "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE \n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "\n",
        "    \n",
        "    \n",
        "    ## Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [128,128,512], s = 2)\n",
        "    X = identity_block(X, 3,  [128,128,512])\n",
        "    X = identity_block(X, 3,  [128,128,512])\n",
        "    X = identity_block(X, 3,  [128,128,512])\n",
        "    \n",
        "    ## Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "\n",
        "    ## Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048])\n",
        "    X = identity_block(X, 3, [512, 512, 2048])\n",
        "\n",
        "    ## AVGPOOL. Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2, 2))(X)\n",
        "    \n",
        "    \n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "WsLgOu-It7w7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooQslyukvoEc",
        "outputId": "0e7d609c-1177-472f-e4ee-4a0773e53c74"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 70, 70, 3)   0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 32, 32, 64)   9472        ['zero_padding2d[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 32, 32, 64)  256         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 15, 15, 64)   0           ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 15, 15, 64)   4160        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 15, 15, 64)  256         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 15, 15, 64)   36928       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 15, 15, 64)  256         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 15, 15, 256)  16640       ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 15, 15, 256)  16640       ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 15, 15, 256)  0           ['batch_normalization_17[0][0]', \n",
            "                                                                  'batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 15, 15, 256)  0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 15, 15, 64)   16448       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 15, 15, 64)  256         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 15, 15, 64)   36928       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 15, 15, 64)  256         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 15, 15, 256)  16640       ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 15, 15, 256)  0           ['activation_15[0][0]',          \n",
            "                                                                  'batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 15, 15, 256)  0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 15, 15, 64)   16448       ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 15, 15, 64)  256         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 15, 15, 64)   36928       ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 15, 15, 64)  256         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 15, 15, 256)  16640       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 15, 15, 256)  0           ['activation_18[0][0]',          \n",
            "                                                                  'batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 15, 15, 256)  0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 8, 8, 128)    32896       ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 8, 8, 128)   512         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 8, 8, 128)   512         ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 8, 8, 512)    131584      ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 8, 8, 512)    0           ['batch_normalization_27[0][0]', \n",
            "                                                                  'batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 8, 8, 512)    0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 8, 8, 128)   512         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 8, 8, 128)   512         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 8, 8, 512)    0           ['activation_24[0][0]',          \n",
            "                                                                  'batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 8, 8, 512)    0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 8, 8, 128)   512         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 8, 8, 128)   512         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_29[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 8, 8, 512)    0           ['activation_27[0][0]',          \n",
            "                                                                  'batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 8, 8, 512)    0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 8, 8, 128)   512         ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 8, 8, 128)   512         ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 8, 8, 512)    0           ['activation_30[0][0]',          \n",
            "                                                                  'batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 8, 8, 512)    0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 4, 4, 256)    131328      ['activation_33[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 4, 4, 1024)   525312      ['activation_33[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 4, 4, 1024)   0           ['batch_normalization_40[0][0]', \n",
            "                                                                  'batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 4, 4, 1024)   0           ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_38[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 4, 4, 1024)   0           ['activation_36[0][0]',          \n",
            "                                                                  'batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 4, 4, 1024)   0           ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_40[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 4, 4, 1024)   0           ['activation_39[0][0]',          \n",
            "                                                                  'batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 4, 4, 1024)   0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_43[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 4, 4, 1024)   0           ['activation_42[0][0]',          \n",
            "                                                                  'batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 4, 4, 1024)   0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 4, 4, 1024)   0           ['activation_45[0][0]',          \n",
            "                                                                  'batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 4, 4, 1024)   0           ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_48[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_50[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 4, 4, 1024)   0           ['activation_48[0][0]',          \n",
            "                                                                  'batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 4, 4, 1024)   0           ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 2, 2, 512)    524800      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_53[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 2, 2, 2048)   2099200     ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 2, 2, 2048)   0           ['batch_normalization_59[0][0]', \n",
            "                                                                  'batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 2, 2, 2048)   0           ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 2, 2, 512)    1049088     ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_18 (Add)                   (None, 2, 2, 2048)   0           ['activation_54[0][0]',          \n",
            "                                                                  'batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 2, 2, 2048)   0           ['add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 2, 2, 512)    1049088     ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_58[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_19 (Add)                   (None, 2, 2, 2048)   0           ['activation_57[0][0]',          \n",
            "                                                                  'batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 2, 2, 2048)   0           ['add_19[0][0]']                 \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 1, 1, 2048)  0           ['activation_60[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2048)         0           ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            12294       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,600,006\n",
            "Trainable params: 23,546,886\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "Id9WTsyqvty7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
        "\n",
        "# Normalize image vectors\n",
        "X_train = X_train_orig / 255.\n",
        "X_test = X_test_orig / 255.\n",
        "\n",
        "# Convert training and test labels to one hot matrices\n",
        "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
        "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
        "\n",
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))\n"
      ],
      "metadata": {
        "id": "46n7EFnnv_eP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, epochs = 10, batch_size = 32)"
      ],
      "metadata": {
        "id": "8dkPQht2wGXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.evaluate(X_test, Y_test)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ],
      "metadata": {
        "id": "xvmxB9VSy06J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_model = tf.keras.models.load_model('resnet50.h5')\n",
        "\n",
        "\n",
        "preds = pre_trained_model.evaluate(X_test, Y_test)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ],
      "metadata": {
        "id": "f5hFojI6y6El"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing on your own images\n",
        "img_path = 'images/my_image.jpg'\n",
        "img = image.load_img(img_path, target_size=(64, 64))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = x/255.0\n",
        "print('Input image shape:', x.shape)\n",
        "imshow(img)\n",
        "prediction = pre_trained_model.predict(x)\n",
        "print(\"Class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = \", prediction)\n",
        "print(\"Class:\", np.argmax(prediction))"
      ],
      "metadata": {
        "id": "ZxNyHwb2y_Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pre_trained_model.summary()"
      ],
      "metadata": {
        "id": "l1wulepZzIUJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}